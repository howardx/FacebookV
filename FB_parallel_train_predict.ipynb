{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from itertools import tee, izip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_id       x       y  accuracy    time    place_id  hour  weekday  month\n",
      "0       0  0.7941  9.0809        54  470702  8523065625    22        5     11\n",
      "1       1  5.9567  4.7968        13  186555  1757726713    14        4      5\n",
      "2       2  8.3078  7.0407        74  322648  1137537235     2        1      8\n",
      "3       3  7.3665  2.5165        65  704587  6567393236     8        7      5\n",
      "4       4  4.0961  1.1307        31  472130  7440663949    21        6     11\n",
      "   row_id       x       y  accuracy    time  hour  weekday  month\n",
      "0       0  0.1675  1.3608       107  930883    11        3     10\n",
      "1       1  7.3909  2.5301        35  893017     4        5      9\n",
      "2       2  8.0978  2.3473        62  976933    11        7     11\n",
      "3       3  0.9990  1.0591        62  907285     2        1     10\n",
      "4       4  0.6670  9.7254        40  914399    24        5     10\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/home/ec2-user/Kaggle/facebook_Jul_2016/feature_engineered_input/hr_wk_mth/train_hr_wk_mth.csv')\n",
    "test = pd.read_csv('/home/ec2-user/Kaggle/facebook_Jul_2016/feature_engineered_input/hr_wk_mth/test_hr_wk_mth.csv')\n",
    "\n",
    "# for real testing set we don't need to do this - it doesn't have place_id info\n",
    "#test = test[['row_id', 'x', 'y', 'accuracy', 'time']]\n",
    "\n",
    "print train.head()\n",
    "print test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import K_fbV.fb_split_grid as sg\n",
    "import K_fbV.factorize_predictor as fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5664, 8)\n"
     ]
    }
   ],
   "source": [
    "# generate the grids\n",
    "train_grid, test_grid = sg.get_grids(train, test, n = 40, m = 40)\n",
    "\n",
    "print test_grid[(2,8)].shape # number of testing set data points in grid (2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import K_fbV.feature_predictor_split as fps\n",
    "import K_fbV.tune_numRound_maxDepth as tnm\n",
    "\n",
    "import K_fbV.train_grid_model as tgm\n",
    "import K_fbV.make_grid_prediction as mgp\n",
    "\n",
    "import K_fbV.gen_submission as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softprob' # tells boosted trees to output probability\n",
    "param['booster'] = 'gbtree' # - default is set to \"gbtree\" - gradient boosted tree\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1 # Parameters for Tree Booster - Booster parameter\n",
    "param['silent'] = 1 # whether to print logs\n",
    "param['nthread'] = 36 # parallelism\n",
    "param['eval_metric'] = 'mlogloss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick smoke test of the entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:4.195870\n",
      "[1]\ttrain-mlogloss:3.484432\n",
      "[2]\ttrain-mlogloss:3.095367\n",
      "[3]\ttrain-mlogloss:2.860185\n",
      "[4]\ttrain-mlogloss:2.688941\n",
      "[5]\ttrain-mlogloss:2.546095\n",
      "[6]\ttrain-mlogloss:2.423606\n",
      "[7]\ttrain-mlogloss:2.315287\n",
      "[8]\ttrain-mlogloss:2.220860\n",
      "[9]\ttrain-mlogloss:2.137168\n",
      "[10]\ttrain-mlogloss:2.062099\n",
      "[11]\ttrain-mlogloss:1.992953\n",
      "[12]\ttrain-mlogloss:1.931711\n",
      "[13]\ttrain-mlogloss:1.872575\n",
      "[14]\ttrain-mlogloss:1.816527\n",
      "[15]\ttrain-mlogloss:1.764913\n",
      "[16]\ttrain-mlogloss:1.716289\n",
      "[17]\ttrain-mlogloss:1.671995\n",
      "[18]\ttrain-mlogloss:1.627555\n",
      "[19]\ttrain-mlogloss:1.587991\n",
      "[20]\ttrain-mlogloss:1.550178\n",
      "[21]\ttrain-mlogloss:1.514879\n",
      "[22]\ttrain-mlogloss:1.480698\n",
      "[23]\ttrain-mlogloss:1.448794\n",
      "[24]\ttrain-mlogloss:1.416662\n",
      "[25]\ttrain-mlogloss:1.386043\n",
      "[26]\ttrain-mlogloss:1.356963\n",
      "[27]\ttrain-mlogloss:1.329431\n",
      "[28]\ttrain-mlogloss:1.303879\n",
      "[29]\ttrain-mlogloss:1.277325\n",
      "[30]\ttrain-mlogloss:1.251948\n",
      "[31]\ttrain-mlogloss:1.227417\n",
      "[32]\ttrain-mlogloss:1.204593\n",
      "[33]\ttrain-mlogloss:1.182724\n",
      "[34]\ttrain-mlogloss:1.160464\n",
      "[35]\ttrain-mlogloss:1.138644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of boosters in training: 37\n",
      "number of boosters in training: 37"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[36]\ttrain-mlogloss:1.118550\n",
      "[0]\ttrain-mlogloss:4.547091\n",
      "[1]\ttrain-mlogloss:3.634774\n",
      "[2]\ttrain-mlogloss:4.403870\n",
      "[3]\ttrain-mlogloss:2.988979\n",
      "[4]\ttrain-mlogloss:2.673471\n",
      "[5]\ttrain-mlogloss:2.531318\n",
      "[6]\ttrain-mlogloss:2.412554\n",
      "[7]\ttrain-mlogloss:2.310858\n",
      "[8]\ttrain-mlogloss:2.221137\n",
      "[9]\ttrain-mlogloss:2.142741\n",
      "[10]\ttrain-mlogloss:2.072070\n",
      "[11]\ttrain-mlogloss:2.008550\n",
      "[12]\ttrain-mlogloss:1.949577\n",
      "[13]\ttrain-mlogloss:1.893833\n",
      "[14]\ttrain-mlogloss:1.843325\n",
      "[15]\ttrain-mlogloss:1.796056\n",
      "[16]\ttrain-mlogloss:1.752271\n",
      "[17]\ttrain-mlogloss:1.710870\n",
      "[18]\ttrain-mlogloss:1.672307\n",
      "[19]\ttrain-mlogloss:1.635218\n",
      "[20]\ttrain-mlogloss:1.600310\n",
      "[21]\ttrain-mlogloss:1.565492\n",
      "[22]\ttrain-mlogloss:1.533899\n",
      "[23]\ttrain-mlogloss:1.503062\n",
      "[24]\ttrain-mlogloss:1.474283\n",
      "[25]\ttrain-mlogloss:1.446629\n",
      "[26]\ttrain-mlogloss:1.418525\n",
      "[27]\ttrain-mlogloss:1.393007\n",
      "[28]\ttrain-mlogloss:1.368435\n",
      "[29]\ttrain-mlogloss:1.344418\n",
      "[30]\ttrain-mlogloss:1.320867\n",
      "[31]\ttrain-mlogloss:1.298674\n",
      "[32]\ttrain-mlogloss:1.277074\n",
      "[33]\ttrain-mlogloss:1.255409\n",
      "[34]\ttrain-mlogloss:1.234553\n",
      "[35]\ttrain-mlogloss:1.214173\n",
      "[36]\ttrain-mlogloss:1.194900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "unique_class_dict = {}\n",
    "\n",
    "tgm.train_model((2, 8), train_grid, param, model_dict, unique_class_dict,\n",
    "            feature_list = ['x', 'y', 'accuracy', 'time', 'hour', 'weekday', 'month'],\n",
    "            predictor_name = 'place_id', leaf_mltpr = 1.5, tree_mltpr = 1.5)\n",
    "\n",
    "tgm.train_model((2, 9), train_grid, param, model_dict, unique_class_dict,\n",
    "            feature_list = ['x', 'y', 'accuracy', 'time', 'hour', 'weekday', 'month'],\n",
    "            predictor_name = 'place_id', leaf_mltpr = 1.5, tree_mltpr = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_dict = {}\n",
    "mgp.predict_output((2, 8), test_grid, model_dict, unique_class_dict, prediction_dict,\n",
    "               test_row_id = 'row_id', feature_list = ['x', 'y', 'accuracy', 'time', 'hour', 'weekday', 'month'])\n",
    "\n",
    "mgp.predict_output((2, 9), test_grid, model_dict, unique_class_dict, prediction_dict,\n",
    "               test_row_id = 'row_id', feature_list = ['x', 'y', 'accuracy', 'time', 'hour', 'weekday', 'month'])\n",
    "\n",
    "print gs.merge_prediction_grids(prediction_dict).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-process Parallalization of the above pipeline to use all cores\n",
    "   - specify a pool of processes using multiprocess package\n",
    "   - need wrapper a function for each function with input parameters more than 1\n",
    "   - use itertools to zip arguments in a list, and in wrapper function unzip/unwrap it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parallel_train(inputs):\n",
    "    \"\"\"Convert f([1,2]) to f(1,2) call\"\"\"\n",
    "    return tgm.train_model(*inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import *\n",
    "from multiprocessing import Queue, Process, freeze_support\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import itertools # for multiple input arguments of the function to be parallilized\n",
    "\n",
    "multiprocessing.cpu_count() # print the number of CPUs availalbe to system\n",
    "\n",
    "freeze_support()\n",
    "pool = Pool( processes = int(multiprocessing.cpu_count() * 0.1) ) # process pool based on number of cores \n",
    "\n",
    "# define input arguments with their associated names in function\n",
    "feature_list = ['x', 'y', 'accuracy', 'time', 'hour', 'weekday', 'month']\n",
    "predictor_name = 'place_id'\n",
    "leaf_mltpr = 1.002\n",
    "tree_mltpr = 1.001\n",
    "\n",
    "pool.map(parallel_train, # function to be parallilized\n",
    "         itertools.izip\n",
    "        (\n",
    "            train_grid.keys(),\n",
    "            itertools.repeat(train_grid),\n",
    "            itertools.repeat(param),\n",
    "            itertools.repeat(model_dict),\n",
    "            itertools.repeat(unique_class_dict),\n",
    "            itertools.repeat(feature_list),\n",
    "            itertools.repeat(predictor_name),\n",
    "            itertools.repeat(leaf_mltpr),\n",
    "            itertools.repeat(tree_mltpr)\n",
    "        )\n",
    "    )\n",
    "print model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
