{
 "metadata": {
  "name": "",
  "signature": "sha256:9acd05996233aa668026a01e83961e190e3c95dd662209e5127d7bbc4490b43d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip\n",
      "import os\n",
      "\n",
      "import ConfigParser\n",
      "\n",
      "from multiprocessing import Manager"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Environment variables store in config file - depends on where we run this ntbk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "config = ConfigParser.ConfigParser()\n",
      "config.read(\"/user_home/w_howardx/git/FacebookV/config/wakari.conf\")\n",
      "\n",
      "param_obj = ConfigParser.ConfigParser()\n",
      "param_obj.read(config.get(\"path\", \"wakari_param_file\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "['/user_home/w_howardx/git/FacebookV/params/param_1.conf']"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print config.get(\"path\", \"wakari_test_grid_path\")\n",
      "print config.sections()\n",
      "print config.options(\"path\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/user_home/w_howardx/model/K_fb_V/10_10_grid/test_grid_files/\n",
        "['path']\n",
        "['wakari_train_file', 'wakari_test_file', 'wakari_param_file', 'wakari_train_grid_path', 'wakari_test_grid_path', 'wakari_model_bite_path', 'wakari_model_txt_path', 'wakari_grid_output_path', 'wakari_output_path']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param = dict(param_obj.items('param'))\n",
      "print param"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'silent': '1', 'eval_metric': 'mlogloss', 'nthread': '4', 'eta': '0.1', 'objective': 'multi:softprob', 'booster': 'gbtree'}\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv(config.get(\"path\", \"wakari_train_file\"))\n",
      "test = pd.read_csv(config.get(\"path\", \"wakari_test_file\"))\n",
      "\n",
      "# for smaller wakari instance\n",
      "train = train.head(5000)\n",
      "test = test.head(5000)\n",
      "print train.shape\n",
      "\n",
      "# for real testing set we don't need to do this - it doesn't have place_id info\n",
      "test = test[['row_id', 'x', 'y', 'accuracy', 'time']]\n",
      "\n",
      "print train.head()\n",
      "print test.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5000, 6)\n",
        "     row_id       x       y  accuracy    time    place_id\n",
        "0  12248539  3.5715  7.8542        32  330246  6473794041\n",
        "1  20937284  2.8401  8.8580        64  665957  7947955924\n",
        "2  24167758  5.4543  6.7475        58  568156  6060796228\n",
        "3  19695255  4.0449  1.6413       170  548963  5914484140\n",
        "4  20624330  9.6725  3.8066       155  642374  8999279958\n",
        "     row_id       x       y  accuracy    time\n",
        "0  12248539  3.5715  7.8542        32  330246\n",
        "1  20937284  2.8401  8.8580        64  665957\n",
        "2  24167758  5.4543  6.7475        58  568156\n",
        "3  19695255  4.0449  1.6413       170  548963\n",
        "4  20624330  9.6725  3.8066       155  642374\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import K_fbV.fb_split_grid as sg # single process split grid - with normal dictionary as output\n",
      "import K_fbV.para_split_grid as psg # multi-process split grid - with multiprocess.Manager.dict() object as output\n",
      "import K_fbV.factorize_predictor as fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate the grids\n",
      "train_grid, test_grid = psg.get_grids(train, test, outputFile = True,\n",
      "                                    train_output = config.get(\"path\", \"wakari_train_grid_path\"),\n",
      "                                    test_output = config.get(\"path\", \"wakari_test_grid_path\"), n = 5, m = 5)\n",
      "\n",
      "print test_grid[(2,3)].shape # number of testing set data points in grid (2, 8)\n",
      "print type(train_grid)\n",
      "print len(train_grid.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(216, 5)\n",
        "<class 'multiprocessing.managers.DictProxy'>\n",
        "25\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import K_fbV.feature_predictor_split as fps\n",
      "import K_fbV.tune_numRound_maxDepth as tnm\n",
      "\n",
      "import K_fbV.train_grid_model as tgm\n",
      "import K_fbV.make_grid_prediction as mgp\n",
      "\n",
      "import K_fbV.gen_submission as gs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param['eta'] = float(param['eta']) # Parameters for Tree Booster - Booster parameter\n",
      "param['silent'] = int(param['silent']) # whether to print logs\n",
      "param['nthread'] = int(param['nthread']) # parallelism"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Quick smoke test of the entire pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "manager = Manager()\n",
      "\n",
      "model_dict = manager.dict() # dictionary object can be shared by multiple processes\n",
      "unique_class_dict = manager.dict() # dictionary object can be shared by multiple processes\n",
      "\n",
      "features = ['x', 'y', 'accuracy', 'time']\n",
      "tgm.train_model((2, 3), train_grid, param, model_dict, unique_class_dict,\n",
      "            feature_list = features, predictor_name = 'place_id',\n",
      "            dump_model_txt = True, model_txt_file = config.get(\"path\", \"wakari_model_txt_path\"),\n",
      "            save_model = True, save_model_file = config.get(\"path\", \"wakari_model_bite_path\"),\n",
      "            leaf_mltpr = 1.01, tree_mltpr = 1.01)\n",
      "\n",
      "features = ['x', 'y', 'accuracy', 'time']\n",
      "tgm.train_model((2, 2), train_grid, param, model_dict, unique_class_dict,\n",
      "            feature_list = features, predictor_name = 'place_id',\n",
      "            dump_model_txt = True, model_txt_file = config.get(\"path\", \"wakari_model_txt_path\"),\n",
      "            save_model = True, save_model_file = config.get(\"path\", \"wakari_model_bite_path\"),\n",
      "            leaf_mltpr = 1.01, tree_mltpr = 1.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[0]\ttrain-mlogloss:5.335702\n",
        "[1]\ttrain-mlogloss:5.309763\n",
        "[2]\ttrain-mlogloss:5.283933\n",
        "[3]\ttrain-mlogloss:5.258005\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of boosters in training: 6\n",
        "number of boosters in training: 6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[4]\ttrain-mlogloss:5.232121\n",
        "[5]\ttrain-mlogloss:5.206274\n",
        "[0]\ttrain-mlogloss:5.313708\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[1]\ttrain-mlogloss:5.284751\n",
        "[2]\ttrain-mlogloss:5.255848\n",
        "[3]\ttrain-mlogloss:5.227037\n",
        "[4]\ttrain-mlogloss:5.198187\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[5]\ttrain-mlogloss:5.169363\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_dict = manager.dict() # dictionary object can be shared by multiple processes\n",
      "\n",
      "features = ['x', 'y', 'accuracy', 'time']\n",
      "mgp.predict_output((2, 3), test_grid, model_dict, unique_class_dict, prediction_dict,\n",
      "               test_row_id = 'row_id', feature_list = features,\n",
      "               saveFile = True, outputPath = config.get(\"path\", \"wakari_grid_output_path\"))\n",
      "\n",
      "features = ['x', 'y', 'accuracy', 'time']\n",
      "mgp.predict_output((2, 2), test_grid, model_dict, unique_class_dict, prediction_dict,\n",
      "               test_row_id = 'row_id', feature_list = features,\n",
      "               saveFile = True, outputPath = config.get(\"path\", \"wakari_grid_output_path\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finalResult = gs.merge_prediction_grids(prediction_dict, save_file = True, output_path = config.get(\"path\", \"wakari_output_path\"))\n",
      "print finalResult.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     row_id           0           1           2\n",
        "21    65822  3768227341  6855049406  8592860518\n",
        "294  162525  7516758468  8109597860  6565827071\n",
        "262  166238  2059189450  1178532394  3526535452\n",
        "332  342662  6086080468  4080100298  4161311947\n",
        "342  448628  9036064828  4161311947  2174294561\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#multi-process Parallalization of the above pipeline to use all cores\n",
      "- specify a pool of processes using multiprocess package\n",
      "- need wrapper a function for each function with input parameters more than 1\n",
      "- use itertools to zip arguments in a list, and in wrapper function unzip/unwrap it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "from functools import wraps\n",
      "\n",
      "def fn_timer(function):\n",
      "    @wraps(function)\n",
      "    def function_timer(*args, **kwargs):\n",
      "        t0 = time.time()\n",
      "        result = function(*args, **kwargs)\n",
      "        t1 = time.time()\n",
      "        print (\"Total time running %s: %s seconds\" %\n",
      "               (function.func_name, str(t1-t0))\n",
      "               )\n",
      "        return result\n",
      "    return function_timer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parallel_train_wrap(inputs): # original function wrapper for catching exceptions and unpack input list\n",
      "    try:\n",
      "        \"\"\"Convert f([1,2]) to f(1,2) call\"\"\"\n",
      "        print \"traninig a grid...\"\n",
      "        tgm.train_model(*inputs) # original function\n",
      "    except:\n",
      "        print inputs[0] # print the tuple value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import multiprocessing\n",
      "from multiprocessing import *\n",
      "from multiprocessing import Queue, Process, freeze_support\n",
      "from multiprocessing import Pool\n",
      "\n",
      "import itertools # for multiple input arguments of the function to be parallilized\n",
      "\n",
      "print multiprocessing.cpu_count() # print the number of CPUs availalbe to system\n",
      "\n",
      "# define input arguments with their associated names in function\n",
      "feature_list = ['x', 'y', 'accuracy', 'time']\n",
      "predictor_name = 'place_id'\n",
      "leaf_mltpr = 1.002\n",
      "tree_mltpr = 1.001"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@fn_timer\n",
      "def timed_parallel_train_wrap():\n",
      "    pool = Pool( processes = int(multiprocessing.cpu_count()) ) # process pool based on number of cores\n",
      "    pool.map\n",
      "    (\n",
      "        parallel_train_wrap, # function to be parallilized\n",
      "        itertools.izip\n",
      "        (\n",
      "            train_grid.keys(),\n",
      "            itertools.repeat(train_grid),\n",
      "            itertools.repeat(param),\n",
      "            itertools.repeat(model_dict),\n",
      "            itertools.repeat(unique_class_dict),\n",
      "            itertools.repeat(feature_list),\n",
      "            itertools.repeat(predictor_name),\n",
      "            itertools.repeat(leaf_mltpr),\n",
      "            itertools.repeat(tree_mltpr)\n",
      "        )\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(model_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'multiprocessing.managers.DictProxy'>\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timed_parallel_train_wrap()\n",
      "print model_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total time running timed_parallel_train_wrap: 0.0995309352875 seconds\n",
        "{(2, 3): <xgboost.core.Booster object at 0x7f76f08e5b10>, (2, 2): <xgboost.core.Booster object at 0x7f76f08e5c90>}\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}