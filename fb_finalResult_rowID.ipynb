{
 "metadata": {
  "name": "",
  "signature": "sha256:4b319662354003d27cfaa21d60fe608962dc2359940bce520abc5a30a521fc93"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv('data/train_100K_sample.csv')\n",
      "test = pd.read_csv('data/train_10K_sample.csv')\n",
      "\n",
      "test = test.sort(['row_id']) # for testing purposes ONLY, not necessary\n",
      "print test.head()\n",
      "\n",
      "# for real testing set we don't need to do this - it doesn't have place_id info\n",
      "test = test[['row_id', 'x', 'y', 'accuracy', 'time']]\n",
      "\n",
      "print min(train['place_id'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      row_id       x       y  accuracy    time    place_id\n",
        "5804    3117  5.6432  0.8774       166  289228  3120099998\n",
        "9433    3259  0.4390  9.8627        75  226515  6099647238\n",
        "6943    4366  4.6299  0.4300        69  496835  4775665237\n",
        "7222    6926  7.3572  9.0972       151  474059  4022153587\n",
        "1119    7907  1.0006  0.2903         1  153427  3536143786\n",
        "1000025138\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import K_fbV.fb_split_grid as sg\n",
      "import K_fbV.factorize_predictor as fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate the grids\n",
      "train_grid, test_grid = sg.get_grids(train, test, n = 50, m = 50)\n",
      "\n",
      "print test_grid[(2,8)].shape # number of testing set data points in grid (2, 8)\n",
      "print len(test_grid) # number of grids form testing set\n",
      "\n",
      "print train_grid[(2,9)].shape\n",
      "print len(train_grid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7, 5)\n",
        "2500\n",
        "(39, 6)\n",
        "2500\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a helper function that splits feature and predictor in training set\n",
      "import pandas as pd\n",
      "\n",
      "def feature_predictor_split(data, predictor_col):\n",
      "    if isinstance(data, pd.DataFrame):\n",
      "        data = data.as_matrix() # convert to numpy ndarray\n",
      "    train_X = data[ :, 0:(predictor_col-1) ]\n",
      "    train_Y = data[ :, predictor_col ]\n",
      "    return (train_X, train_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Relationship between max_depth, num_round and num_class\n",
      "   - num_class has to be at least fully covered once by all the weak boosters (assume each leaf node yields a different class, then num_class = number of leafes in all booster trees\n",
      "   - for each binary tree (xgb uses binary tee only) of depth k, there will be 2^k leafes at max - max happen when tree is balanced\n",
      "   - so the number of leafes for N depth k trees will be N*(2^k), and num_class has to be less or equal to this number\n",
      "   - num_round and max_depth will always have tradeoff, larger max_depth may result in overfit, larger num_round will take longer time to train"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# method to tune relation ship between num_round and max_depth\n",
      "import math\n",
      "\n",
      "def tune_numRound_maxDepth(num_class, max_depth = 5, num_leaf_mltpr = 1, num_tree_mltpr = 1):\n",
      "    num_leafes = num_class * num_leaf_mltpr\n",
      "\n",
      "    max_leaf_per_tree = math.pow(2, max_depth)\n",
      "\n",
      "    num_tree = int ( (num_leafes / max_leaf_per_tree) * num_tree_mltpr )\n",
      "    return (num_tree, max_depth)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this method is the task to be parallelized in multiple processes\n",
      "# It trains xgb model for a single grid block and fills two dictionaries -\n",
      "# {(x,y) : xgb model}\n",
      "# {(x,y) : list of unique classes for that grid - in original labels}\n",
      "\n",
      "import xgboost as xgb\n",
      "\n",
      "def train_model(coord_tup, train_grid, param, model_dict, unique_class_dict, feature_list,\n",
      "                predictor_name, predictor_idx, dump_model_txt = False, \n",
      "                model_txt_file = None, save_model = False, save_model_file = None,\n",
      "                tree_max_depth = 5, leaf_mltpr = 1, tree_mltpr = 1):\n",
      "    feature_list.append(predictor_name) # can only have 1 predictor\n",
      "    grid = train_grid[coord_tup][feature_list]\n",
      "    \n",
      "    train, original_label = fp.factorize_predictor(grid, predictor_idx)\n",
      "    param['num_class'] = len(original_label)\n",
      "    \n",
      "    num_round, param['max_depth'] = tune_numRound_maxDepth(param['num_class'], num_leaf_mltpr = leaf_mltpr)\n",
      "\n",
      "    train_X, train_Y = feature_predictor_split(train, predictor_idx)\n",
      "    xg_train = xgb.DMatrix( train_X, label = train_Y)\n",
      "\n",
      "    # specify traing (and testing) set for model training \n",
      "    watchlist = [ (xg_train,'train') ]\n",
      "    \n",
      "    # fill {(x,y) : xgb_model}\n",
      "    model_dict[coord_tup] = xgb.train(param, xg_train, num_round, watchlist)\n",
      "    # {(x,y) : list of unique classes for that grid - in original labels}\n",
      "    unique_class_dict[coord_tup] = original_label\n",
      "    \n",
      "    if dump_model_txt:\n",
      "        bst.dump_model(model_txt_file)\n",
      "    if save_model:\n",
      "        bst.save_model(save_model_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param = {}\n",
      "# use softmax multi-class classification\n",
      "param['objective'] = 'multi:softprob' # tells boosted trees to output probability\n",
      "param['booster'] = 'gbtree' # - default is set to \"gbtree\" - gradient boosted tree\n",
      "# scale weight of positive examples\n",
      "param['eta'] = 0.1 # Parameters for Tree Booster - Booster parameter\n",
      "param['silent'] = 1 # whether to print logs\n",
      "param['nthread'] = 4 # parallelism\n",
      "param['eval_metric'] = 'mlogloss'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_dict = {}\n",
      "unique_class_dict = {}\n",
      "\n",
      "train_model((2, 8), train_grid, param, model_dict, unique_class_dict,\n",
      "            feature_list = ['x', 'y', 'accuracy', 'time'], predictor_name = 'place_id',\n",
      "            predictor_idx = 4, leaf_mltpr = 2, tree_mltpr = 2)\n",
      "\n",
      "train_model((2, 9), train_grid, param, model_dict, unique_class_dict,\n",
      "            feature_list = ['x', 'y', 'accuracy', 'time'], predictor_name = 'place_id',\n",
      "            predictor_idx = 4, leaf_mltpr = 2, tree_mltpr = 2)\n",
      "\n",
      "print model_dict\n",
      "print type(unique_class_dict[(2,8)])\n",
      "print unique_class_dict[(2,8)].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{(2, 8): <xgboost.core.Booster object at 0x7f957a97ba50>, (2, 9): <xgboost.core.Booster object at 0x7f957a97b410>}\n",
        "<type 'numpy.ndarray'>\n",
        "(34,)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[0]\ttrain-mlogloss:3.451460\n",
        "[1]\ttrain-mlogloss:3.378759\n",
        "[0]\ttrain-mlogloss:2.932092\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_top_k_idx(ndarray_idx, k):\n",
      "    return ndarray_idx[:, -k:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Predictions generated from each grid in testing set need to be identified such that final results can be aggregated from all grids."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this method is the task to be parallelized in multiple processes\n",
      "# It uses xgb model for a single grid block and generate a dictionary of \n",
      "#{(x,y) : xgb model prediction result for testing set (pd.DF)}\n",
      "\n",
      "import xgboost as xgb\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "def predict_output(coord_tup, test_grid, model_dict, unique_class_dict, prediction_dict, \n",
      "                   test_row_id, feature_list, saveFile = False, outputPath = None):\n",
      "    rowID = test_grid[coord_tup][test_row_id].tolist() # ignore existing pandas indicies\n",
      "    grid = test_grid[coord_tup][feature_list]\n",
      "    \n",
      "    test_X = xgb.DMatrix( grid.as_matrix() )\n",
      "    preds_prob = model_dict[coord_tup].predict(test_X)\n",
      "    \n",
      "    sortedProbIdx = np.argsort(preds_prob)\n",
      "    topKprob_idx = get_top_k_idx(sortedProbIdx, 3)\n",
      "    \n",
      "    unique_class = unique_class_dict[coord_tup]\n",
      "    predictions = unique_class[topKprob_idx]\n",
      "    \n",
      "    df_predictions = pd.DataFrame(predictions, index = None)\n",
      "    df_predictions.insert(0, test_row_id, rowID)\n",
      "    \n",
      "    prediction_dict[coord_tup] = df_predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_dict = {}\n",
      "predict_output((2, 8), test_grid, model_dict, unique_class_dict, prediction_dict,\n",
      "               test_row_id = 'row_id', feature_list = ['x', 'y', 'accuracy', 'time'])\n",
      "\n",
      "predict_output((2, 9), test_grid, model_dict, unique_class_dict, prediction_dict,\n",
      "               test_row_id = 'row_id', feature_list = ['x', 'y', 'accuracy', 'time'])\n",
      "\n",
      "print prediction_dict[(2, 8)][0:5]\n",
      "print prediction_dict[(2, 9)][0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     row_id           0           1           2\n",
        "0   4731259  2562283122  3485822022  6671223183\n",
        "1   6056808  3937671506  6792751429  9551909561\n",
        "2  11738607  2562283122  3485822022  6671223183\n",
        "3  11858284  6671223183  1664706508  8510146684\n",
        "4  20411536  2562283122  3485822022  6671223183\n",
        "     row_id           0           1           2\n",
        "0   6737920  2805069625  4683526794  5009843028\n",
        "1   9727023  2805069625  4683526794  5009843028\n",
        "2  10394124  4683526794  9622628998  5009843028\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "def merge_prediction_grids(predict_dict, sort_rowID = False, save_file = False, output_path = None):\n",
      "    df_finalResult = pd.concat(predict_dict.values(), ignore_index = True)\n",
      "    \n",
      "    if sort_rowID:\n",
      "        df_finalResult = df_finalResult.sort(['row_id']) # for testing purposes ONLY, not necessary\n",
      "    \n",
      "    if save_file:\n",
      "        df_finalResult.to_csv(output_path, index = False) # no pandas index in CSV file\n",
      "    return df_finalResult            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print merge_prediction_grids(prediction_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     row_id           0           1           2\n",
        "0   4731259  2562283122  3485822022  6671223183\n",
        "1   6056808  3937671506  6792751429  9551909561\n",
        "2  11738607  2562283122  3485822022  6671223183\n",
        "3  11858284  6671223183  1664706508  8510146684\n",
        "4  20411536  2562283122  3485822022  6671223183\n",
        "5  21516599  3937671506  6792751429  9551909561\n",
        "6  26232341  8265802703  1146384983  8510146684\n",
        "7   6737920  2805069625  4683526794  5009843028\n",
        "8   9727023  2805069625  4683526794  5009843028\n",
        "9  10394124  4683526794  9622628998  5009843028\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}