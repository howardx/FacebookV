{
 "metadata": {
  "name": "",
  "signature": "sha256:dbe282a78d26715aaf635963670bd707440bc0438385da5b84ff19c9f39a5010"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('/user_home/w_howardx/data/train_10K_sample.csv')\n",
      "print df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     row_id       x       y  accuracy    time    place_id\n",
        "0  12248539  3.5715  7.8542        32  330246  6473794041\n",
        "1  20937284  2.8401  8.8580        64  665957  7947955924\n",
        "2  24167758  5.4543  6.7475        58  568156  6060796228\n",
        "3  19695255  4.0449  1.6413       170  548963  5914484140\n",
        "4  20624330  9.6725  3.8066       155  642374  8999279958\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print min(df['x'])\n",
      "print max(df['x'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0029\n",
        "9.9983\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_count, x_bin_cutoff = np.histogram(df[\"x\"], bins = 10)\n",
      "y_count, y_bin_cutoff = np.histogram(df[\"y\"], bins = 10)\n",
      "\n",
      "print x_count\n",
      "print len(x_count)\n",
      "\n",
      "print x_bin_cutoff\n",
      "print len(x_bin_cutoff) # cutoff values are inclusive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 994  974 1002 1015 1021 1054  961 1034 1005  940]\n",
        "10\n",
        "[  2.90000000e-03   1.00244000e+00   2.00198000e+00   3.00152000e+00\n",
        "   4.00106000e+00   5.00060000e+00   6.00014000e+00   6.99968000e+00\n",
        "   7.99922000e+00   8.99876000e+00   9.99830000e+00]\n",
        "11\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this function takes a iterable, return its stepwise pair tuple in a list\n",
      "# [1, 2, 3, 4, 5] -> [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "def pairwise(iterable):\n",
      "    floor, ceiling = tee(iterable)\n",
      "    next(ceiling, None)\n",
      "    return izip(floor, ceiling)\n",
      "\n",
      "x_bin_tuple = [(f, c) for f, c in pairwise(x_bin_cutoff)]\n",
      "y_bin_tuple = [(f, c) for f, c in pairwise(y_bin_cutoff)]\n",
      "\n",
      "print x_bin_tuple\n",
      "print len(x_bin_tuple)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0.0028999999999999998, 1.00244), (1.00244, 2.0019800000000001), (2.0019800000000001, 3.0015199999999997), (3.0015199999999997, 4.0010599999999998), (4.0010599999999998, 5.0006000000000004), (5.0006000000000004, 6.00014), (6.00014, 6.9996800000000006), (6.9996800000000006, 7.9992200000000002), (7.9992200000000002, 8.9987600000000008), (8.9987600000000008, 9.9983000000000004)]\n",
        "10\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_1st = x_bin_tuple[0]\n",
      "y_1st = y_bin_tuple[0]\n",
      "\n",
      "x_1st_bin = df[ (df['x'] > x_1st[0]) & (df['x'] <= x_1st[1]) ]\n",
      "# within x_1st_bin, there should be 10 y bins, forming 10 grids - all fall in x_1st_bin\n",
      "# for each x_bin, there should be 10 y bins \"within\" - forming overall 100 (10 x 10) bins\n",
      "\n",
      "grid_1 = x_1st_bin[ (x_1st_bin['y'] > y_1st[0]) & (x_1st_bin['y'] <= y_1st[1]) ]\n",
      "\n",
      "print x_1st_bin.head()\n",
      "print x_1st_bin.shape\n",
      "\n",
      "print grid_1.head()\n",
      "print grid_1.shape\n",
      "\n",
      "print min(x_1st_bin['x']) # floor exclusive - need special treatment for both the first x and y bin\n",
      "print max(x_1st_bin['x']) # ceiling inclusive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      row_id       x       y  accuracy    time    place_id\n",
        "34   8198164  0.0477  0.0016        15   70081  5349374802\n",
        "44   6753159  0.7981  3.7757         3    9781  8044475613\n",
        "53  28981286  0.8861  6.6071        72  726478  9097932228\n",
        "65   6639631  0.8711  2.9592        56  383579  2486482960\n",
        "66  20375310  0.3114  5.9561       324  775597  2555889317\n",
        "(993, 6)\n",
        "       row_id       x       y  accuracy    time    place_id\n",
        "34    8198164  0.0477  0.0016        15   70081  5349374802\n",
        "87   11229207  0.5011  0.9077        72   87578  1424356113\n",
        "337  16051202  0.5984  0.2401        78  740241  1481132469\n",
        "360  27195793  0.0213  0.8260        70  679745  6843751929\n",
        "361  26695923  0.3554  0.3748        13  389794  8293305885\n",
        "(95, 6)\n",
        "0.0091\n",
        "1.0024\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# This function takes a filename/path, and generate N*M number of output files (or a dictionary or N*M pandas dataframes) forming a NxM grid base on x and y coordinates in input file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip\n",
      "import os\n",
      "\n",
      "# a helper function takes an iterable, return its stepwise pair tuple in a list\n",
      "# [1, 2, 3, 4, 5] -> [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "def pairwise(iterable):\n",
      "    floor, ceiling = tee(iterable)\n",
      "    next(ceiling, None)\n",
      "    return izip(floor, ceiling)\n",
      "\n",
      "# a helper function takes a df, a column name, a list of floor/ceiling values \n",
      "# \"split\" the df based on the given column, using the list of floor/ceiling values, return list of df\n",
      "#\n",
      "# flr_clg will be floor EXclusive, ceiling INclusive - need special treatment for the first split\n",
      "def split_df_rows_on_col_ranges(df, col, flr_clg):\n",
      "    splitted_df = []\n",
      "    first = True\n",
      "    for fc in flr_clg:\n",
      "        if first:\n",
      "            splitted_df.append(df[ (df[col] >= fc[0]) & (df[col] <= fc[1]) ])\n",
      "            first = False\n",
      "        else:\n",
      "            splitted_df.append(df[ (df[col] > fc[0]) & (df[col] <= fc[1]) ])\n",
      "    return splitted_df\n",
      "    \n",
      "'''\n",
      "input parameters for def get_grids():\n",
      "- filename - input filename with path (probably the training set)\n",
      "\n",
      "- outputPath - only used if the 3rd parameter is set to True, will be the path to store NxM files, \n",
      "               each file contains a grid of data points\n",
      "               \n",
      "- outputFile - boolean that tells whether you want NxN files as output or a dict of pd.DataFrame\n",
      "               as output, format would be (x_idx, y_idx) : df_for_grid. If you want file as output\n",
      "               then x_idx, y_idx will appear in output files' name\n",
      "               \n",
      "- n - NxM grid, the N value, for x axis\n",
      "\n",
      "- m - NxM grid, the M value, for y axis\n",
      "\n",
      "- x - column name of the x coordinate in input file\n",
      "\n",
      "- y - column name of the y coordinate in input file\n",
      "\n",
      "'''\n",
      "def get_grids(filename, outputFile = False, outputPath = None, n = 10, m = 10, x = 'x', y = 'y'):\n",
      "    df = pd.read_csv(filename)\n",
      "    \n",
      "    # getting the cutoff values for x and y axis\n",
      "    x_count, x_cutoff = np.histogram(df[x], bins = n)\n",
      "    y_count, y_cutoff = np.histogram(df[y], bins = m)\n",
      "    \n",
      "    # transform cutoff values into step-wise tuples\n",
      "    x_bin_tuple = [(floor, ceiling) for floor, ceiling in pairwise(x_cutoff)]\n",
      "    y_bin_tuple = [(floor, ceiling) for floor, ceiling in pairwise(y_cutoff)]\n",
      "    \n",
      "    gridDict = {} # final output\n",
      "    \n",
      "    x_splits = split_df_rows_on_col_ranges(df, x, x_bin_tuple) # getting list of N bars based on x values\n",
      "    \n",
      "    # within each bar splitted based on x, there will be N splits based on y - each within which is a grid\n",
      "    xidx = 0\n",
      "    for xbar in x_splits:        \n",
      "        # getting list of N bars (grids here already) based on y values, all within 1 xbar\n",
      "        y_splits_in_xbar = split_df_rows_on_col_ranges(xbar, y, y_bin_tuple)\n",
      "            \n",
      "        yidx = 0\n",
      "        for grid in y_splits_in_xbar:\n",
      "            gridDict[(xidx, yidx)] = grid # gather output with x,y index\n",
      "            yidx = yidx + 1     \n",
      "        xidx = xidx + 1\n",
      "        \n",
      "    if outputFile:\n",
      "        for key in gridDict:\n",
      "            filename = 'x' + str(key[0]) + '_y' + str(key[1]) + '_grid.csv'\n",
      "            fullpath = os.path.join(outputPath, filename)\n",
      "            gridDict[key].to_csv(fullpath, index = False)\n",
      "    else:\n",
      "        return gridDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# quick test\n",
      "grids = get_grids('data/train_10K_sample.csv')\n",
      "print grids[(2,8)].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       row_id       x       y  accuracy    time    place_id\n",
        "1    20937284  2.8401  8.8580        64  665957  7947955924\n",
        "122  26826549  2.0518  8.8263        15  237145  8163579295\n",
        "268  22912562  2.2872  8.9907        62  438251  8637115336\n",
        "273   9956263  2.7245  8.5318        69  366563  9370287575\n",
        "279  27207943  2.5826  8.5842        50  123841  6499869557\n",
        "      row_id       x       y  accuracy    time    place_id\n",
        "18   9112019  7.0526  9.8496         7  441848  5500791663\n",
        "33   2238972  6.5798  9.0472        12  379712  6151612400\n",
        "36   6218468  8.3123  9.2526        60  528465  4628904477\n",
        "37   4079647  5.5067  9.9404        67  750325  4042395085\n",
        "45  10727389  7.8306  9.6714        17   53285  3444100675\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# after cutting grid using training set, also need to fit testing set data into these grids so as to determine which model to use for testing set (each grid there is a different model)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# need to make sure that all testing set data are subsets of training set data in terms of x, y coordinate\n",
      "test = pd.read_csv('data/train_100K_sample.csv')\n",
      "print test.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     row_id       x       y  accuracy    time    place_id\n",
        "0   9160363  3.5582  3.7109         6  165878  2576740489\n",
        "1  11059323  4.4331  6.7376        64  386737  4677187676\n",
        "2    319918  7.3856  2.9418        65  273133  5801802830\n",
        "3    472956  7.8793  6.3885        64  784848  1089479233\n",
        "4  22692915  3.0219  7.6451        40  400398  4404322782\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate the grids\n",
      "grids = get_grids('data/train_10K_sample.csv', n = 2, m = 9)\n",
      "print grids[(1,8)].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      row_id       x       y  accuracy    time    place_id\n",
        "18   9112019  7.0526  9.8496         7  441848  5500791663\n",
        "33   2238972  6.5798  9.0472        12  379712  6151612400\n",
        "36   6218468  8.3123  9.2526        60  528465  4628904477\n",
        "37   4079647  5.5067  9.9404        67  750325  4042395085\n",
        "45  10727389  7.8306  9.6714        17   53285  3444100675\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# This function takes 2 filename/path, training and testing set, and generate 2*N*M number of output files (or two dictionaries of N*M pandas dataframes) forming a NxM grid base on x and y coordinates in input files\n",
      "   - files names, or dictionary keys, will be unique grid id, in the format of (0, 0), (0, 1), (0, 2) ... Can be used to access both testing and training set data in the corresponding grid\n",
      "   - IMPORTANT ASSUMPTION, testing set MUST be subset of training set in terms of x and y coordinates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip\n",
      "import os\n",
      "\n",
      "# a helper function takes an iterable, return its stepwise pair tuple in a list\n",
      "# [1, 2, 3, 4, 5] -> [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "def pairwise(iterable):\n",
      "    floor, ceiling = tee(iterable)\n",
      "    next(ceiling, None)\n",
      "    return izip(floor, ceiling)\n",
      "\n",
      "# a helper function takes a df, a column name, a list of floor/ceiling values \n",
      "# \"split\" the df based on the given column, using the list of floor/ceiling values, return list of df\n",
      "#\n",
      "# flr_clg will be floor EXclusive, ceiling INclusive - need special treatment for the first split\n",
      "def split_df_rows_on_col_ranges(df, col, flr_clg):\n",
      "    splitted_df = []\n",
      "    first = True\n",
      "    for fc in flr_clg:\n",
      "        if first:\n",
      "            splitted_df.append(df[ (df[col] >= fc[0]) & (df[col] <= fc[1]) ])\n",
      "            first = False\n",
      "        else:\n",
      "            splitted_df.append(df[ (df[col] > fc[0]) & (df[col] <= fc[1]) ])\n",
      "    return splitted_df\n",
      "\n",
      "# a helper function takes x bars, cut y bars inside and return a dictionary of grids\n",
      "def cut_y_bars_in_x_bar(x_bars, y, y_bin_tuple):\n",
      "    gridDict = {}\n",
      "    xidx = 0\n",
      "    for xbar in x_bars:        \n",
      "        # getting list of N bars (grids here already) based on y values, all within 1 xbar\n",
      "        y_bars_in_xbar = split_df_rows_on_col_ranges(xbar, y, y_bin_tuple)\n",
      "            \n",
      "        yidx = 0\n",
      "        for grid in y_bars_in_xbar:\n",
      "            gridDict[(xidx, yidx)] = grid # gather output with x,y index\n",
      "            yidx = yidx + 1     \n",
      "        xidx = xidx + 1\n",
      "    return gridDict\n",
      "\n",
      "'''\n",
      "input parameters for def get_grids():\n",
      "- train_file - input filename with path for the training set\n",
      "\n",
      "- test_file - input filename with path for the test set\n",
      "\n",
      "- outputFile - boolean that tells whether you want NxM files as output or a dict of pd.DataFrame\n",
      "               as output, format would be (x_idx, y_idx) : df_for_grid. If you want file as output\n",
      "               then x_idx, y_idx will appear in output files' name\n",
      "\n",
      "- train_output - only used if the 3rd parameter is set to True, will be the path to store NxM files for training set,\n",
      "                 each file contains a grid of data points\n",
      "\n",
      "- test_output - only used if the 3rd parameter is set to True, will be the path to store NxM files for testing set,\n",
      "                each file contains a grid of data points\n",
      "\n",
      "- n - NxM grid, the N value, for x axis\n",
      "\n",
      "- m - NxM grid, the M value, for y axis\n",
      "\n",
      "- x - column name of the x coordinate in input file\n",
      "\n",
      "- y - column name of the y coordinate in input file\n",
      "\n",
      "'''\n",
      "def get_grids(train_file, test_file, outputFile = False, train_output = None, test_output = None, n = 10, m = 10, x = 'x', y = 'y'):\n",
      "    train = pd.read_csv(train_file)\n",
      "    test = pd.read_csv(test_file)\n",
      "    \n",
      "    # getting the cutoff values for x and y axis, using training set ONLY - because of the IMPORTANT ASSUMPTION -\n",
      "    # TESTING SET IS SUBSET OF TRAINING SET IN TERMS OF X AND Y COORDINATES\n",
      "    x_count, x_cutoff = np.histogram(train[x], bins = n)\n",
      "    y_count, y_cutoff = np.histogram(train[y], bins = m)\n",
      "\n",
      "    # transform cutoff values into step-wise tuples\n",
      "    x_bin_tuple = [(floor, ceiling) for floor, ceiling in pairwise(x_cutoff)]\n",
      "    y_bin_tuple = [(floor, ceiling) for floor, ceiling in pairwise(y_cutoff)]\n",
      "\n",
      "    train_x_splits = split_df_rows_on_col_ranges(train, x, x_bin_tuple) # getting list of N bars based on x values for train\n",
      "    test_x_splits = split_df_rows_on_col_ranges(test, x, x_bin_tuple) # getting list of N bars based on x values for test\n",
      "\n",
      "    # within each bar (overall N) splitted based on x, there will be M splits based on y - each one is a grid\n",
      "    trainDict = cut_y_bars_in_x_bar(train_x_splits, y, y_bin_tuple)\n",
      "    testDict = cut_y_bars_in_x_bar(test_x_splits, y, y_bin_tuple)\n",
      "\n",
      "    if outputFile:\n",
      "        for key in trainDict:\n",
      "            filename = 'train_' + 'x' + str(key[0]) + '_y' + str(key[1]) + '_grid.csv'\n",
      "            fullpath = os.path.join(train_output, filename)\n",
      "            trainDict[key].to_csv(fullpath, index = False)\n",
      "        for key in testDict:\n",
      "            filename = 'test_' + 'x' + str(key[0]) + '_y' + str(key[1]) + '_grid.csv'\n",
      "            fullpath = os.path.join(test_output, filename)\n",
      "            testDict[key].to_csv(fullpath, index = False)\n",
      "    else:\n",
      "        return (trainDict, testDict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate the grids\n",
      "train_grid, test_grid = get_grids('data/train_100K_sample.csv', 'data/train_10K_sample.csv')\n",
      "\n",
      "print test_grid[(0,4)].shape # number of testing set data points in grid 1, 8)\n",
      "print len(test_grid) # number of grids form testing set\n",
      "\n",
      "print train_grid[(0,4)].shape\n",
      "print len(train_grid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(86, 6)\n",
        "100\n",
        "(996, 6)\n",
        "100\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip\n",
      "import os\n",
      "\n",
      "# a helper function takes an iterable, return its stepwise pair tuple in a list\n",
      "# [1, 2, 3, 4, 5] -> [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "def pairwise(iterable):\n",
      "    floor, ceiling = tee(iterable)\n",
      "    next(ceiling, None)\n",
      "    return izip(floor, ceiling)\n",
      "\n",
      "# a helper function takes a df, a column name, a list of floor/ceiling values\n",
      "# \"split\" the df based on the given column, using the list of floor/ceiling values, return list of df\n",
      "#\n",
      "# flr_clg will be floor EXclusive, ceiling INclusive - need special treatment for the first split\n",
      "def split_df_rows_on_col_ranges(df, col, flr_clg):\n",
      "    splitted_df = []\n",
      "    first = True\n",
      "    for fc in flr_clg:\n",
      "        if first:\n",
      "            splitted_df.append(df[ (df[col] >= fc[0]) & (df[col] <= fc[1]) ])\n",
      "            first = False\n",
      "        else:\n",
      "            splitted_df.append(df[ (df[col] > fc[0]) & (df[col] <= fc[1]) ])\n",
      "    return splitted_df\n",
      "\n",
      "# a helper function takes x bars, cut y bars inside and return a dictionary of grids\n",
      "def cut_y_bars_in_x_bar(x_bars, y, y_bin_tuple):\n",
      "    gridDict = {}\n",
      "    xidx = 0\n",
      "    for xbar in x_bars:\n",
      "        # getting list of N bars (grids here already) based on y values, all within 1 xbar\n",
      "        y_bars_in_xbar = split_df_rows_on_col_ranges(xbar, y, y_bin_tuple)\n",
      "\n",
      "        yidx = 0\n",
      "        for grid in y_bars_in_xbar:\n",
      "            gridDict[(xidx, yidx)] = grid # gather output with x,y index\n",
      "            yidx = yidx + 1\n",
      "        xidx = xidx + 1\n",
      "    return gridDict\n",
      "\n",
      "'''\n",
      "input parameters for def get_grids():\n",
      "- train - input filename/dataframe for training set\n",
      "- test - input filename/dataframe for test set\n",
      "- outputFile - boolean that tells whether you want NxM files as output or a dict of pd.DataFrame\n",
      "               as output, format would be (x_idx, y_idx) : df_for_grid. If you want file as output\n",
      "               then x_idx, y_idx will appear in output files' name\n",
      "- train_output - only used if the 3rd parameter is set to True, will be the path to store NxM files for training set,\n",
      "                 each file contains a grid of data points\n",
      "- test_output - only used if the 3rd parameter is set to True, will be the path to store NxM files for testing set,\n",
      "                each file contains a grid of data points\n",
      "- n - NxM grid, the N value, for x axis\n",
      "- m - NxM grid, the M value, for y axis\n",
      "- x - column name of the x coordinate in input file\n",
      "- y - column name of the y coordinate in input file\n",
      "'''\n",
      "def get_grids(train, test, outputFile = False, train_output = None, test_output = None, n = 10, m = 10, x = 'x', y = 'y'):\n",
      "    if isinstance(train, basestring):\n",
      "        train = pd.read_csv(train)\n",
      "    if isinstance(test, basestring):\n",
      "        test = pd.read_csv(test)\n",
      "\n",
      "    # getting the cutoff values for x and y axis, using training set ONLY - because of the IMPORTANT ASSUMPTION -\n",
      "    # TESTING SET IS SUBSET OF TRAINING SET IN TERMS OF X AND Y COORDINATES\n",
      "    x_count, x_cutoff = np.histogram(train[x], bins = n)\n",
      "    y_count, y_cutoff = np.histogram(train[y], bins = m)\n",
      "\n",
      "    # transform cutoff values into step-wise tuples\n",
      "    x_bin_tuple = [(floor, ceiling) for floor, ceiling in pairwise(x_cutoff)]\n",
      "    y_bin_tuple = [(floor, ceiling) for floor, ceiling in pairwise(y_cutoff)]\n",
      "\n",
      "    train_x_splits = split_df_rows_on_col_ranges(train, x, x_bin_tuple) # getting list of N bars based on x values for train\n",
      "    test_x_splits = split_df_rows_on_col_ranges(test, x, x_bin_tuple) # getting list of N bars based on x values for test\n",
      "\n",
      "    # within each bar (overall N) splitted based on x, there will be M splits based on y - each one is a grid\n",
      "    trainDict = cut_y_bars_in_x_bar(train_x_splits, y, y_bin_tuple)\n",
      "    testDict = cut_y_bars_in_x_bar(test_x_splits, y, y_bin_tuple)\n",
      "\n",
      "    if outputFile:\n",
      "        for key in trainDict:\n",
      "            filename = 'train_' + 'x' + str(key[0]) + '_y' + str(key[1]) + '.csv'\n",
      "            fullpath = os.path.join(train_output, filename)\n",
      "            trainDict[key].to_csv(fullpath, index = False)\n",
      "        for key in testDict:\n",
      "            filename = 'test_' + 'x' + str(key[0]) + '_y' + str(key[1]) + '.csv'\n",
      "            fullpath = os.path.join(test_output, filename)\n",
      "            testDict[key].to_csv(fullpath, index = False)\n",
      "    return (trainDict, testDict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv('/user_home/w_howardx/data/train_10K_sample.csv')\n",
      "test = pd.read_csv('/user_home/w_howardx/data/train_10K_sample.csv')\n",
      "\n",
      "test = test[['row_id', 'x', 'y', 'accuracy', 'time']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate the grids\n",
      "train_grid, test_grid = get_grids(train, test)\n",
      "\n",
      "df = train_grid[(0,4)]\n",
      "print df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       row_id       x       y  accuracy    time    place_id\n",
        "132  17240780  0.1737  4.8975       379  764578  9132939685\n",
        "162   8453586  0.4756  4.2035        54  365889  1946238480\n",
        "321  26962273  0.5678  4.0236        71  522078  4433667163\n",
        "451  25850769  0.5453  4.6916       238  771188  9089305028\n",
        "544  11964684  0.9398  4.6837        55  468583  1399978025\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Function for taking at least the first K percentile of placeIDs in a grid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['pid_count'] = df.groupby('place_id')['place_id'].transform(pd.Series.value_counts)\n",
      "df.sort_values(by = ['pid_count', 'place_id'], ascending = False, inplace = True)\n",
      "\n",
      "testdf = df.head(4)\n",
      "print testdf\n",
      "\n",
      "numRow = testdf.shape[0]\n",
      "print testdf.shape\n",
      "print numRow"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "        row_id       x       y  accuracy    time    place_id  pid_count\n",
        "796   10642030  0.1112  4.4495        71   25852  5747383903          2\n",
        "3407   1619552  0.1431  4.4469        70  502565  5747383903          2\n",
        "2094  27703590  0.5603  4.5281        65  119692  3478133066          2\n",
        "9730   6404060  0.5581  4.5163        55  646492  3478133066          2\n",
        "(4, 7)\n",
        "4\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "percentile = 80 \n",
      "proportion = 0.01 * percentile\n",
      "\n",
      "numRow_in_proportion = int(proportion * numRow)\n",
      "border_rowIdx = numRow_in_proportion - 1\n",
      "\n",
      "print border_rowIdx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# iloc() selects row by integer index, NOT labled index - for labeled index use loc()\n",
      "border_target_value = testdf.iloc[[border_rowIdx]]['place_id']\n",
      "print border_target_value.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[3478133066]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}