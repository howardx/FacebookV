{
 "metadata": {
  "name": "",
  "signature": "sha256:eeb2bda20b13a3cc4d9f56611ea848a63d12bacf9f6763494972dddc3a266639"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('/user_home/w_howardx/data/train_10K_sample.csv')\n",
      "print df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print min(df['x'])\n",
      "print max(df['x'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_count, x_bin_cutoff = np.histogram(df[\"x\"], bins = 10)\n",
      "y_count, y_bin_cutoff = np.histogram(df[\"y\"], bins = 10)\n",
      "\n",
      "print x_count\n",
      "print len(x_count)\n",
      "\n",
      "print x_bin_cutoff\n",
      "print len(x_bin_cutoff) # cutoff values are inclusive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this function takes a iterable, return its stepwise pair tuple in a list\n",
      "# [1, 2, 3, 4, 5] -> [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "def pairwise(iterable):\n",
      "    floor, ceiling = tee(iterable)\n",
      "    next(ceiling, None)\n",
      "    return izip(floor, ceiling)\n",
      "\n",
      "x_bin_tuple = [(f, c) for f, c in pairwise(x_bin_cutoff)]\n",
      "y_bin_tuple = [(f, c) for f, c in pairwise(y_bin_cutoff)]\n",
      "\n",
      "print x_bin_tuple\n",
      "print len(x_bin_tuple)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_1st = x_bin_tuple[0]\n",
      "y_1st = y_bin_tuple[0]\n",
      "\n",
      "x_1st_bin = df[ (df['x'] > x_1st[0]) & (df['x'] <= x_1st[1]) ]\n",
      "# within x_1st_bin, there should be 10 y bins, forming 10 grids - all fall in x_1st_bin\n",
      "# for each x_bin, there should be 10 y bins \"within\" - forming overall 100 (10 x 10) bins\n",
      "\n",
      "grid_1 = x_1st_bin[ (x_1st_bin['y'] > y_1st[0]) & (x_1st_bin['y'] <= y_1st[1]) ]\n",
      "\n",
      "print x_1st_bin.head()\n",
      "print x_1st_bin.shape\n",
      "\n",
      "print grid_1.head()\n",
      "print grid_1.shape\n",
      "\n",
      "print min(x_1st_bin['x']) # floor exclusive - need special treatment for both the first x and y bin\n",
      "print max(x_1st_bin['x']) # ceiling inclusive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# This function takes 2 filename/path, training and testing set, and generate 2*N*M number of output files (or two dictionaries of N*M pandas dataframes) forming a NxM grid base on x and y coordinates in input files\n",
      "   - files names, or dictionary keys, will be unique grid id, in the format of (0, 0), (0, 1), (0, 2) ... Can be used to access both testing and training set data in the corresponding grid\n",
      "   - IMPORTANT ASSUMPTION, testing set MUST be subset of training set in terms of x and y coordinates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip\n",
      "import os\n",
      "\n",
      "# a helper function takes an iterable, return its stepwise pair tuple in a list\n",
      "# [1, 2, 3, 4, 5] -> [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "def pairwise(iterable):\n",
      "    floor, ceiling = tee(iterable)\n",
      "    next(ceiling, None)\n",
      "    return izip(floor, ceiling)\n",
      "\n",
      "# a helper function takes a df, a column name, a list of floor/ceiling values\n",
      "# \"split\" the df based on the given column, using the list of floor/ceiling values, return list of df\n",
      "#\n",
      "# flr_clg will be floor EXclusive, ceiling INclusive - need special treatment for the first split\n",
      "def split_df_rows_on_col_ranges(df, col, flr_clg):\n",
      "    splitted_df = []\n",
      "    first = True\n",
      "    for fc in flr_clg:\n",
      "        if first:\n",
      "            splitted_df.append(df[ (df[col] >= fc[0]) & (df[col] <= fc[1]) ])\n",
      "            first = False\n",
      "        else:\n",
      "            splitted_df.append(df[ (df[col] > fc[0]) & (df[col] <= fc[1]) ])\n",
      "    return splitted_df\n",
      "\n",
      "# a helper function takes x bars, cut y bars inside and return a dictionary of grids\n",
      "def cut_y_bars_in_x_bar(x_bars, y, y_bin_tuple):\n",
      "    gridDict = {}\n",
      "    xidx = 0\n",
      "    for xbar in x_bars:\n",
      "        # getting list of N bars (grids here already) based on y values, all within 1 xbar\n",
      "        y_bars_in_xbar = split_df_rows_on_col_ranges(xbar, y, y_bin_tuple)\n",
      "\n",
      "        yidx = 0\n",
      "        for grid in y_bars_in_xbar:\n",
      "            gridDict[(xidx, yidx)] = grid # gather output with x,y index\n",
      "            yidx = yidx + 1\n",
      "        xidx = xidx + 1\n",
      "    return gridDict\n",
      "\n",
      "'''\n",
      "input parameters for def get_grids():\n",
      "- train - input filename/dataframe for training set\n",
      "- test - input filename/dataframe for test set\n",
      "- outputFile - boolean that tells whether you want NxM files as output or a dict of pd.DataFrame\n",
      "               as output, format would be (x_idx, y_idx) : df_for_grid. If you want file as output\n",
      "               then x_idx, y_idx will appear in output files' name\n",
      "- train_output - only used if the 3rd parameter is set to True, will be the path to store NxM files\n",
      "                 for training set, each file contains a grid of data points\n",
      "- test_output - only used if the 3rd parameter is set to True, will be the path to store NxM files\n",
      "                for testing set, each file contains a grid of data points\n",
      "- n - NxM grid, the N value, for x axis\n",
      "- m - NxM grid, the M value, for y axis\n",
      "- x - column name of the x coordinate in input file\n",
      "- y - column name of the y coordinate in input file\n",
      "'''\n",
      "def get_grids(train, test, outputFile = False, train_output = None, test_output = None,\n",
      "              n = 10, m = 10, x = 'x', y = 'y'):\n",
      "    if isinstance(train, basestring):\n",
      "        train = pd.read_csv(train)\n",
      "    if isinstance(test, basestring):\n",
      "        test = pd.read_csv(test)\n",
      "\n",
      "    # getting the cutoff values for x and y axis, using training set ONLY - because of the\n",
      "    # IMPORTANT ASSUMPTION - TESTING SET IS SUBSET OF TRAINING SET IN TERMS OF X AND Y COORDINATES\n",
      "    x_count, x_cutoff = np.histogram(train[x], bins = n)\n",
      "    y_count, y_cutoff = np.histogram(train[y], bins = m)\n",
      "\n",
      "    # transform cutoff values into step-wise tuples\n",
      "    x_bin_tuple = [(floor, ceiling) for floor, ceiling in pairwise(x_cutoff)]\n",
      "    y_bin_tuple = [(floor, ceiling) for floor, ceiling in pairwise(y_cutoff)]\n",
      "\n",
      "    # getting list of N bars based on x values for train\n",
      "    train_x_splits = split_df_rows_on_col_ranges(train, x, x_bin_tuple)\n",
      "    # getting list of N bars based on x values for test\n",
      "    test_x_splits = split_df_rows_on_col_ranges(test, x, x_bin_tuple)\n",
      "    \n",
      "    # within each bar (overall N) splitted based on x, there will be M splits\n",
      "    # based on y - each one is a grid\n",
      "    trainDict = cut_y_bars_in_x_bar(train_x_splits, y, y_bin_tuple)\n",
      "    testDict = cut_y_bars_in_x_bar(test_x_splits, y, y_bin_tuple)\n",
      "\n",
      "    if outputFile:\n",
      "        for key in trainDict:\n",
      "            filename = 'train_' + 'x' + str(key[0]) + '_y' + str(key[1]) + '.csv'\n",
      "            fullpath = os.path.join(train_output, filename)\n",
      "            trainDict[key].to_csv(fullpath, index = False)\n",
      "        for key in testDict:\n",
      "            filename = 'test_' + 'x' + str(key[0]) + '_y' + str(key[1]) + '.csv'\n",
      "            fullpath = os.path.join(test_output, filename)\n",
      "            testDict[key].to_csv(fullpath, index = False)\n",
      "    return (trainDict, testDict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv('/user_home/w_howardx/data/train_10K_sample.csv')\n",
      "test = pd.read_csv('/user_home/w_howardx/data/train_10K_sample.csv')\n",
      "\n",
      "test = test[['row_id', 'x', 'y', 'accuracy', 'time']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate the grids\n",
      "train_grid, test_grid = get_grids(train, test)\n",
      "\n",
      "df = train_grid[(0,4)]\n",
      "print df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Function for taking -at least- the first K percentile of placeIDs in a grid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['pid_count'] = df.groupby('place_id')['place_id'].transform(pd.Series.value_counts)\n",
      "print df.shape\n",
      "\n",
      "df.sort_values(by = ['pid_count', 'place_id'], ascending = False, inplace = True)\n",
      "\n",
      "testdf = df.head(4)\n",
      "\n",
      "numRow = testdf.shape[0]\n",
      "print testdf.shape\n",
      "print testdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "percentile = 20 \n",
      "percentile_idx = int(0.01 * percentile * numRow) - 1\n",
      "if percentile_idx < 0:\n",
      "    percentile_idx = 0 # in case the number of rows are too few\n",
      "\n",
      "print percentile_idx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# edge case handling -- at percentile index there could be a chunk of a unique placeID - need to include that entire chunk into final result"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "# iloc() selects row by integer index, NOT labled index - for labeled index use loc()\n",
      "percentil_border_value = testdf.iloc[[percentile_idx]]['place_id']\n",
      "\n",
      "print percentil_border_value\n",
      "\n",
      "# getting the percentil position place_id value, see if there were more than one instances\n",
      "# reason to use np.where() is because it returns row index, not row label from pandas.DataFrame\n",
      "percentil_border_chunk = np.where(testdf['place_id'] == percentil_border_value.values[0])\n",
      "\n",
      "# np.where() always returns a tuple of arrays, because you can directly plug its result back in\n",
      "# to your original array as index and perform select\n",
      "percentil_border = max(percentil_border_chunk[0])\n",
      "\n",
      "print percentil_border"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testdf[:percentil_border + 1] # pandas.DataFrame row slice is end exclusive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# putting top percentile place_id selection altogether -WRONG-"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "def top_K_percentile_pid(grid, k_p = 80, pid = 'place_id'):\n",
      "    grid['pid_count'] = grid.groupby(pid)[pid].transform(pd.Series.value_counts)\n",
      "\n",
      "    grid.sort_values(by = ['pid_count', pid], ascending = False, inplace = True)\n",
      "    numRow = grid.shape[0]\n",
      " \n",
      "    percentile_idx = int(0.01 * k_p * numRow) - 1\n",
      "    if percentile_idx < 0:\n",
      "        percentile_idx = 0 # in case the number of rows are too few\n",
      "    \n",
      "    # iloc() selects row by integer index, NOT labled index - for labeled index use loc()\n",
      "    percentil_border_value = grid.iloc[[percentile_idx]][pid]\n",
      "\n",
      "    # getting the percentil position place_id value, see if there were more than one instances\n",
      "    # reason to use np.where() is because it returns row index, not row label from pandas.DataFrame\n",
      "    percentil_border_chunk = np.where(grid[pid] == percentil_border_value.values[0])\n",
      "\n",
      "    # np.where() always returns a tuple of arrays, because you can directly plug its result back in\n",
      "    # to your original array as index and perform select\n",
      "    percentil_border = max(percentil_border_chunk[0])\n",
      "    \n",
      "    grid.drop('pid_count', axis = 1, inplace = True)\n",
      "    \n",
      "    return grid[:percentil_border + 1] # pandas.DataFrame row slice is end exclusive"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = train_grid[(0,4)]\n",
      "print df.shape\n",
      "\n",
      "df50 = top_K_percentile_pid(df, k_p = .1)\n",
      "print df50.shape\n",
      "\n",
      "df80 = top_K_percentile_pid(df)\n",
      "print df80.shape\n",
      "\n",
      "print df50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}