{
 "metadata": {
  "name": "",
  "signature": "sha256:d6fde485257af83e3a8378b532f2ec7f7d7d05db251e4a261501d75fd82d3c9d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from itertools import tee, izip\n",
      "import os\n",
      "\n",
      "import ConfigParser"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Environment variables store in config file - depends on where we run this ntbk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "config = ConfigParser.ConfigParser()\n",
      "config.read(\"/user_home/w_howardx/git/FacebookV/config/wakari.conf\")\n",
      "\n",
      "param_obj = ConfigParser.ConfigParser()\n",
      "param_obj.read(config.get(\"path\", \"wakari_param_file\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "['/user_home/w_howardx/git/FacebookV/params/param_1.conf']"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print config.get(\"path\", \"wakari_test_grid_path\")\n",
      "print config.sections()\n",
      "print config.options(\"path\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/user_home/w_howardx/model/K_fb_V/10_10_grid/test_grid_files/\n",
        "['path']\n",
        "['wakari_train_file', 'wakari_test_file', 'wakari_param_file', 'wakari_train_grid_path', 'wakari_test_grid_path', 'wakari_model_bite_path', 'wakari_model_txt_path', 'wakari_grid_output_path', 'wakari_output_path']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param = dict(param_obj.items('param'))\n",
      "print param"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'silent': '1', 'eval_metric': 'mlogloss', 'nthread': '4', 'eta': '0.1', 'objective': 'multi:softprob', 'booster': 'gbtree'}\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv(config.get(\"path\", \"wakari_train_file\"))\n",
      "test = pd.read_csv(config.get(\"path\", \"wakari_test_file\"))\n",
      "\n",
      "# for real testing set we don't need to do this - it doesn't have place_id info\n",
      "test = test[['row_id', 'x', 'y', 'accuracy', 'time']]\n",
      "\n",
      "print train.head()\n",
      "print test.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     row_id       x       y  accuracy    time    place_id\n",
        "0  12248539  3.5715  7.8542        32  330246  6473794041\n",
        "1  20937284  2.8401  8.8580        64  665957  7947955924\n",
        "2  24167758  5.4543  6.7475        58  568156  6060796228\n",
        "3  19695255  4.0449  1.6413       170  548963  5914484140\n",
        "4  20624330  9.6725  3.8066       155  642374  8999279958\n",
        "     row_id       x       y  accuracy    time\n",
        "0  12248539  3.5715  7.8542        32  330246\n",
        "1  20937284  2.8401  8.8580        64  665957\n",
        "2  24167758  5.4543  6.7475        58  568156\n",
        "3  19695255  4.0449  1.6413       170  548963\n",
        "4  20624330  9.6725  3.8066       155  642374\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import K_fbV.fb_split_grid as sg\n",
      "import K_fbV.factorize_predictor as fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate the grids\n",
      "train_grid, test_grid = sg.get_grids(train, test, outputFile = True,\n",
      "                                    train_output = config.get(\"path\", \"wakari_train_grid_path\"),\n",
      "                                    test_output = config.get(\"path\", \"wakari_test_grid_path\"), n = 10, m = 10)\n",
      "\n",
      "print test_grid[(2,8)].shape # number of testing set data points in grid (2, 8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(91, 5)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import K_fbV.feature_predictor_split as fps\n",
      "import K_fbV.tune_numRound_maxDepth as tnm\n",
      "\n",
      "import K_fbV.train_grid_model as tgm\n",
      "import K_fbV.make_grid_prediction as mgp\n",
      "\n",
      "import K_fbV.gen_submission as gs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param['eta'] = float(param['eta']) # Parameters for Tree Booster - Booster parameter\n",
      "param['silent'] = int(param['silent']) # whether to print logs\n",
      "param['nthread'] = int(param['nthread']) # parallelism"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Quick smoke test of the entire pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_dict = {}\n",
      "unique_class_dict = {}\n",
      "\n",
      "features = ['x', 'y', 'accuracy', 'time']\n",
      "tgm.train_model((2, 9), train_grid, param, model_dict, unique_class_dict,\n",
      "            feature_list = features, predictor_name = 'place_id',\n",
      "            dump_model_txt = True, model_txt_file = config.get(\"path\", \"wakari_model_txt_path\"),\n",
      "            save_model = True, save_model_file = config.get(\"path\", \"wakari_model_bite_path\"),\n",
      "            leaf_mltpr = 1.01, tree_mltpr = 1.01)\n",
      "\n",
      "features = ['x', 'y', 'accuracy', 'time']\n",
      "tgm.train_model((2, 8), train_grid, param, model_dict, unique_class_dict,\n",
      "            feature_list = features, predictor_name = 'place_id',\n",
      "            dump_model_txt = True, model_txt_file = config.get(\"path\", \"wakari_model_txt_path\"),\n",
      "            save_model = True, save_model_file = config.get(\"path\", \"wakari_model_bite_path\"),\n",
      "            leaf_mltpr = 1.01, tree_mltpr = 1.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of boosters in training: 3\n",
        "number of boosters in training: 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[0]\ttrain-mlogloss:4.611643\n",
        "[1]\ttrain-mlogloss:4.578755\n",
        "[2]\ttrain-mlogloss:4.546031\n",
        "[0]\ttrain-mlogloss:4.449973\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[1]\ttrain-mlogloss:4.422537\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_dict = {}\n",
      "\n",
      "features = ['x', 'y', 'accuracy', 'time']\n",
      "mgp.predict_output((2, 8), test_grid, model_dict, unique_class_dict, prediction_dict,\n",
      "               test_row_id = 'row_id', feature_list = features,\n",
      "               saveFile = True, outputPath = config.get(\"path\", \"wakari_grid_output_path\"))\n",
      "\n",
      "features = ['x', 'y', 'accuracy', 'time']\n",
      "mgp.predict_output((2, 9), test_grid, model_dict, unique_class_dict, prediction_dict,\n",
      "               test_row_id = 'row_id', feature_list = features,\n",
      "               saveFile = True, outputPath = config.get(\"path\", \"wakari_grid_output_path\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finalResult = gs.merge_prediction_grids(prediction_dict, save_file = True, output_path = config.get(\"path\", \"wakari_output_path\"))\n",
      "print finalResult.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     row_id           0           1           2\n",
        "61   126583  8672684223  2379270583  8637115336\n",
        "142  182607  7490199494  9652456628  5673467208\n",
        "72   208045  4665394584  9129780742  8772469670\n",
        "121  775239  4735607850  7490199494  6632061186\n",
        "157  829811  1040256643  3977545714  7376066454\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "K_fbV/gen_submission.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
        "  df_finalResult = df_finalResult.sort(['row_id'])\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#multi-process Parallalization of the above pipeline to use all cores\n",
      "- specify a pool of processes using multiprocess package\n",
      "- need wrapper a function for each function with input parameters more than 1\n",
      "- use itertools to zip arguments in a list, and in wrapper function unzip/unwrap it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parallel_train(inputs):\n",
      "    \"\"\"Convert f([1,2]) to f(1,2) call\"\"\"\n",
      "    return tgm.train_model(*inputs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import multiprocessing\n",
      "from multiprocessing import *\n",
      "from multiprocessing import Queue, Process, freeze_support\n",
      "from multiprocessing import Pool\n",
      "\n",
      "import itertools # for multiple input arguments of the function to be parallilized\n",
      "\n",
      "multiprocessing.cpu_count() # print the number of CPUs availalbe to system\n",
      "\n",
      "freeze_support()\n",
      "pool = Pool( processes = int(multiprocessing.cpu_count()) ) # process pool based on number of cores \n",
      "\n",
      "# define input arguments with their associated names in function\n",
      "feature_list = ['x', 'y', 'accuracy', 'time']\n",
      "predictor_name = 'place_id'\n",
      "leaf_mltpr = 1.002\n",
      "tree_mltpr = 1.001\n",
      "\n",
      "pool.map(parallel_train, # function to be parallilized\n",
      "         itertools.izip\n",
      "        (\n",
      "            train_grid.keys(),\n",
      "            itertools.repeat(train_grid),\n",
      "            itertools.repeat(param),\n",
      "            itertools.repeat(model_dict),\n",
      "            itertools.repeat(unique_class_dict),\n",
      "            itertools.repeat(feature_list),\n",
      "            itertools.repeat(predictor_name),\n",
      "            itertools.repeat(leaf_mltpr),\n",
      "            itertools.repeat(tree_mltpr)\n",
      "        )\n",
      "    )\n",
      "print model_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}